{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cd72f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "0    9058\n",
      "1     942\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Loading full dataset \n",
    "df = pd.read_csv(\"C://Users//Bhargavi//Downloads//IR_DATASET.csv\")\n",
    "\n",
    "# Taking a random sample of 10,000 rows \n",
    "df_subset = df.sample(n=10000, random_state=42)\n",
    "\n",
    "# Checking the distribution of target classes\n",
    "print(df_subset['toxic'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd8fcbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Bhargavi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119105    geez forgetful already discussed marx anarchis...\n",
      "131631    carioca rfa thanks support request adminship f...\n",
      "125326                 birthday worries enjoy ur day talk e\n",
      "111256    pseudoscience category assuming article pseudo...\n",
      "83590     phrase exists would provided search engine eve...\n",
      "Name: comment_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Downloading stopwords \n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Removing special characters, digits, and extra spaces\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = re.sub(r'\\d+', ' ', text)\n",
    "    \n",
    "    # Tokenizing and removing stopwords\n",
    "    tokens = text.split()\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Applying preprocessing to the 'comment_text' column\n",
    "df_subset['comment_text'] = df_subset['comment_text'].apply(preprocess_text)\n",
    "\n",
    "# Checking if preprocessing is applied correctly\n",
    "print(df_subset['comment_text'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f4c53d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initializing TF-IDF Vectorizer \n",
    "vectorizer = TfidfVectorizer(max_features=10000)\n",
    "\n",
    "# Transforming the comments into TF-IDF features\n",
    "X = vectorizer.fit_transform(df_subset['comment_text'])\n",
    "\n",
    "# Defining the target variable \n",
    "y = df_subset['toxic']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f33c4d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 10000) (2000, 10000) (8000,) (2000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Spliting the data into 80% training and 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Checking the sizes of the splits\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ab6b209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best Hyperparameters: {'C': 10, 'penalty': 'l1'}\n",
      "Logistic Regression Accuracy: 0.944\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      1801\n",
      "           1       0.79      0.60      0.68       199\n",
      "\n",
      "    accuracy                           0.94      2000\n",
      "   macro avg       0.87      0.79      0.82      2000\n",
      "weighted avg       0.94      0.94      0.94      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initializing the Logistic Regression model\n",
    "log_reg_model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Defining the hyperparameter grid for tuning\n",
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100], 'penalty': ['l1', 'l2']}\n",
    "\n",
    "# Using GridSearchCV for hyperparameter tuning (5-fold cross-validation)\n",
    "grid_search = GridSearchCV(log_reg_model, param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Training the model using grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# To get the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Using the best model from grid search to make predictions\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred_log_reg = best_model.predict(X_test)\n",
    "\n",
    "# Evaluating the accuracy and performance\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_log_reg))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_log_reg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94f48b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.9185\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      1801\n",
      "           1       1.00      0.18      0.31       199\n",
      "\n",
      "    accuracy                           0.92      2000\n",
      "   macro avg       0.96      0.59      0.63      2000\n",
      "weighted avg       0.93      0.92      0.89      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Initializing and training Naive Bayes model\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the Naive Bayes model\n",
    "print(\"Naive Bayes Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1beded-7b2a-44da-96a1-3acb5742e72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "from PIL import Image, ImageTk  # For handling images\n",
    "import os\n",
    "\n",
    "# Function to preprocess the input text\n",
    "def preprocess_text(text):\n",
    "    # Adding the logic here, such as lowercasing, removing special characters, etc.\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "# Function to predict toxicity of the input text\n",
    "def predict_toxicity():\n",
    "    input_text = entry.get(\"1.0\", \"end-1c\").strip()  # Get text from the text box\n",
    "    if input_text == \"\":\n",
    "        messagebox.showwarning(\"Input Error\", \"Please enter a comment.\")\n",
    "        return\n",
    "    \n",
    "    preprocessed_text = preprocess_text(input_text)  # Preprocess the input text\n",
    "    text_vector = vectorizer.transform([preprocessed_text])  # Transform to TF-IDF\n",
    "    prediction = best_model.predict(text_vector)  # Make prediction\n",
    "    \n",
    "    if prediction[0] == 1:\n",
    "        messagebox.showinfo(\"Prediction Result\", \"The comment is Toxic.\")\n",
    "    else:\n",
    "        messagebox.showinfo(\"Prediction Result\", \"The comment is Non-Toxic.\")\n",
    "\n",
    "# Setting up the GUI\n",
    "root = tk.Tk()\n",
    "root.title(\"Toxicity Classifier\")\n",
    "\n",
    "# Making the window full screen\n",
    "root.attributes('-fullscreen', True)\n",
    "\n",
    "# Loading the background image\n",
    "image_path = \"C://Users//Bhargavi//Downloads//image_toxic.PNG\"  \n",
    "if os.path.exists(image_path):\n",
    "    try:\n",
    "        background_image = Image.open(image_path)\n",
    "        # Resizing the image to cover the full screen\n",
    "        screen_width = root.winfo_screenwidth()\n",
    "        screen_height = root.winfo_screenheight()\n",
    "        background_image = background_image.resize((screen_width, screen_height), Image.Resampling.LANCZOS)\n",
    "        bg_image = ImageTk.PhotoImage(background_image)\n",
    "\n",
    "        # Create a label to display the background image\n",
    "        background_label = tk.Label(root, image=bg_image)\n",
    "        background_label.place(x=0, y=0, relwidth=1, relheight=1)\n",
    "\n",
    "        # Keep a reference to avoid garbage collection\n",
    "        background_label.image = bg_image\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image: {e}\")\n",
    "else:\n",
    "    print(\"Image not found\")\n",
    "\n",
    "# Creating a frame in the center for text box and buttons\n",
    "center_frame = tk.Frame(root, bg=\"#008080\", padx=20, pady=20)\n",
    "center_frame.place(relx=0.5, rely=0.3, anchor=\"center\")\n",
    "\n",
    "# Creating a label inside the frame\n",
    "label = tk.Label(center_frame, text=\"Enter your comment:\", bg=\"#e6f2ff\", font=(\"Arial\", 16))\n",
    "label.pack(pady=10)\n",
    "\n",
    "# Creating a text box for input\n",
    "entry = tk.Text(center_frame, height=8, width=50, font=(\"Arial\", 14))\n",
    "entry.pack(pady=10)\n",
    "\n",
    "# Creating a button to trigger prediction\n",
    "button = tk.Button(center_frame, text=\"Check Toxicity\", command=predict_toxicity, bg=\"#66b3ff\", font=(\"Arial\", 12))\n",
    "button.pack(pady=10)\n",
    "\n",
    "# Creating a button to close the application\n",
    "def close_app():\n",
    "    root.destroy()\n",
    "\n",
    "close_button = tk.Button(center_frame, text=\"Close\", command=close_app, bg=\"red\", font=(\"Arial\", 12))\n",
    "close_button.pack(pady=10)\n",
    "\n",
    "# Centering the messagebox dialog\n",
    "root.eval('tk::PlaceWindow . center')\n",
    "\n",
    "# Run the application\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fb29c7-00c9-4ce6-b2b5-8ae8c7942f88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
